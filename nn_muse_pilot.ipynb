{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b5ad59-7ca1-4758-8dba-eba6f53e4a13",
   "metadata": {},
   "source": [
    "# Cognitive Load Estimation Using Muse EEG\n",
    "\n",
    "The paper focuses on EEG recordings for classifying baseline vs cognitive load states, primarily using raw EEG data from specific channels.\n",
    "The raw data at each time stamp dn consists of dn = {pi, tp9, af7, af8, tp10}. So this would be columns:\n",
    "\n",
    "- RAW_TP9\n",
    "- RAW_AF7\n",
    "- RAW_AF8\n",
    "- RAW_TP10\n",
    "\n",
    "Additionally, the paper emphasizes:\n",
    "- Theta (4-7.5Hz) and Alpha (8-13Hz) frequency bands as important for identifying cognitive load.\n",
    "\n",
    "Therefore, in addition to the raw data, we consider extracting features from the following columns:\n",
    "Theta: Theta_TP9, Theta_AF7, Theta_AF8, Theta_TP10\n",
    "Alpha: Alpha_TP9, Alpha_AF7, Alpha_AF8, Alpha_TP10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f00dd-8f2e-4701-af08-592510d94b9a",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e201542-499f-48de-8d5b-a0328403b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, iirnotch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62479508-9bcb-4e9b-9012-120af7131fca",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Using the pilot data set first for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468e31ff-c87e-4084-9a0a-260c0d7190a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define paths and init empty lists to store data\n",
    "base_path = 'pilot'\n",
    "participants = range(11)\n",
    "columns_to_keep = [\n",
    "    'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
    "    'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10',\n",
    "    'Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10',\n",
    "    'Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10',\n",
    "    'Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8', 'Gamma_TP10'\n",
    "]\n",
    "sampling_rate = 256  # Hz, from CogWear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20a51ae-687d-4801-a6ca-e3154beb599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters\n",
    "# To remove 50Hz powerline noise\n",
    "def notch_filter(data, freq=50.0, Q=30.0, fs=256.0):\n",
    "    w0 = freq / (fs / 2) # Normalize\n",
    "    b, a = iirnotch(w0, Q)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "# Band-pass filter function (1-50 Hz)\n",
    "def bandpass_filter(data, lowcut=1.0, highcut=50.0, fs=256.0, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return lfilter(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d895b6-6a91-4305-8351-cc88b93af609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "def apply_filters(eeg_data):\n",
    "    filtered_data = pd.DataFrame()\n",
    "    for column in eeg_data.columns:\n",
    "        eeg_filtered = notch_filter(eeg_data[column], freq=50.0, fs=sampling_rate)\n",
    "        eeg_filtered = bandpass_filter(eeg_filtered, lowcut=1.0, highcut=50.0,  fs=sampling_rate)\n",
    "        filtered_data[column] = eeg_filtered\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e39f03-aed5-4b9f-866b-d97542aed5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and Process Data\n",
    "def load_and_filter_data(participant_id, state):\n",
    "    file_path = os.path.join(base_path, str(participant_id), state, 'muse_eeg.csv')\n",
    "    eeg_data = pd.read_csv(file_path)\n",
    "    # Select columns to keep\n",
    "    eeg_data = eeg_data[columns_to_keep]\n",
    "    \n",
    "    # Check for missing values and drop them\n",
    "    missing_values_before = eeg_data.isnull().sum().sum()\n",
    "    eeg_data.dropna(inplace=True)\n",
    "    missing_values_after = eeg_data.isnull().sum().sum()\n",
    "    \n",
    "    # Apply filters to each channel in the EEG data\n",
    "    eeg_data_filtered = apply_filters(eeg_data)\n",
    "    return eeg_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d472f7b3-fa13-47ed-a176-92f293e6497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into 1 second epochs as mentioned in the paper\n",
    "# Assign labels, baseline (0) & cognitive_load (1)\n",
    "# Discard values that do not create a consistent epoch size of 256\n",
    "def create_epochs_and_labels(eeg_data, label, segment_duration=1):\n",
    "    num_samples_per_epoch = int(sampling_rate * segment_duration)\n",
    "    total_samples = len(eeg_data)\n",
    "    \n",
    "    truncated_length = total_samples - (total_samples % num_samples_per_epoch)\n",
    "\n",
    "    data_epochs = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(truncated_length // num_samples_per_epoch):\n",
    "        start = i * num_samples_per_epoch\n",
    "        end = start + num_samples_per_epoch\n",
    "        data_epochs.append(eeg_data.iloc[start:end].to_numpy())\n",
    "        labels.append(label)\n",
    "        \n",
    "    return np.array(data_epochs), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b826d-7692-4bcc-a2f9-a297de72ded2",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Based on paper \"Wearable EEG-Based Cognitive Load Classification by Personalized and\n",
    "Generalized Model Using Brain Asymmetry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5f6eec-3a7c-43ba-b639-4a90831c09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filtered_data):\n",
    "    \"\"\"Extract features from the filtered data using PSD values.\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Calculate mean power for each frequency band across the specified channels\n",
    "    features['Delta'] = filtered_data[['Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10']].mean(axis=1)\n",
    "    features['Theta'] = filtered_data[['Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10']].mean(axis=1)\n",
    "    features['Alpha'] = filtered_data[['Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10']].mean(axis=1)\n",
    "    features['Beta'] = filtered_data[['Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10']].mean(axis=1)\n",
    "    features['Gamma'] = filtered_data[['Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8', 'Gamma_TP10']].mean(axis=1)\n",
    "\n",
    "    # Calculate ratios\n",
    "    features['Alpha_Beta_Ratio'] = features['Alpha'] / features['Beta']\n",
    "    features['Theta_Beta_Ratio'] = features['Theta'] / features['Beta']\n",
    "    features['Theta_Alpha_Beta_Ratio'] = (features['Theta'] + features['Alpha']) / features['Beta']\n",
    "    features['Theta_Alpha_Alpha_Beta_Ratio'] = (features['Theta'] + features['Alpha']) / (features['Beta'] + features['Alpha'])\n",
    "    features['Theta_Alpha_Ratio'] = features['Theta'] / features['Alpha']\n",
    "    features['Alpha_Theta_Ratio'] = features['Alpha'] / features['Theta']\n",
    "\n",
    "    # Log-transform alpha power for AF8 and AF7\n",
    "    features['Log_Alpha_AF7'] = np.log(np.where(filtered_data['Alpha_AF7'] > 0, filtered_data['Alpha_AF7'], 1e-10))\n",
    "    features['Log_Alpha_AF8'] = np.log(np.where(filtered_data['Alpha_AF8'] > 0, filtered_data['Alpha_AF8'], 1e-10))\n",
    "    features['Asymmetry_Score'] = features['Log_Alpha_AF7'] - features['Log_Alpha_AF8']\n",
    "\n",
    "    return pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b52dc3-1c43-44cd-a050-3167cda93573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27872\\4071042656.py:4: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eeg_data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Shape of input data (X): (4179, 256, 14)\n",
      "Shape of labels (y): (4179,)\n"
     ]
    }
   ],
   "source": [
    "# Main processing loop\n",
    "muse_data = []  # To store all epochs and labels\n",
    "X_features = []  # To store all extracted features\n",
    "y_labels = []    # To store all corresponding labels\n",
    "\n",
    "\n",
    "# Loop through all participants and process their data\n",
    "for participant in participants:\n",
    "    # Load and filter baseline and cognitive load data\n",
    "    baseline_data_filtered = load_and_filter_data(participant, 'baseline')\n",
    "    cognitive_load_data_filtered = load_and_filter_data(participant, 'cognitive_load')\n",
    "\n",
    "    # Extract features from the entire filtered data (before chunking)\n",
    "    baseline_features = extract_features(baseline_data_filtered)\n",
    "    cognitive_load_features = extract_features(cognitive_load_data_filtered)\n",
    "\n",
    "    # Create epochs and assign labels for baseline and cognitive load data\n",
    "    baseline_data_epochs, baseline_labels = create_epochs_and_labels(baseline_features, label=0)\n",
    "    cognitive_load_data_epochs, cognitive_load_labels = create_epochs_and_labels(cognitive_load_features, label=1)\n",
    "\n",
    "    # Append both baseline and cognitive load data epochs for the participant\n",
    "    muse_data.append((baseline_data_epochs, baseline_labels))\n",
    "    muse_data.append((cognitive_load_data_epochs, cognitive_load_labels))\n",
    "\n",
    "# Check for empty epochs before concatenation\n",
    "X_list = [epoch for epoch, _ in muse_data if epoch.size > 0]\n",
    "y_list = [label for _, label in muse_data]\n",
    "\n",
    "# Ensure we have the same number of dimensions and valid data\n",
    "if X_list:\n",
    "    X = np.concatenate(X_list)\n",
    "    y = np.concatenate(y_list)\n",
    "else:\n",
    "    X = np.array([])  # Handle the case where no data is present\n",
    "    y = np.array([])\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "print(f\"Shape of input data (X): {X.shape}\")\n",
    "print(f\"Shape of labels (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da149b5-00f0-45fe-82ff-4dfc33b9839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf321e6-46b7-41cf-b48b-880fbc788316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the time dimension\n",
    "X_flat = X.reshape(X.shape[0], -1)  # Shape: (4179, 3584)\n",
    "\n",
    "# Now X_flat and y are ready for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ddd2af9-32cd-4f11-83c6-0a60b458db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Stratified K-Fold for balanced class distribution\n",
    "kf = StratifiedKFold(n_splits=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d6f47-bedc-41e0-be22-fce5514ee9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers with default parameters\n",
    "svm = SVC(kernel='linear')  # You can change to 'rbf' if desired\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# For storing results\n",
    "svm_accuracies = []\n",
    "rf_accuracies = []\n",
    "\n",
    "# Loop over the folds for SVM\n",
    "for train_index, test_index in kf.split(X_flat, y):\n",
    "    X_train, X_test = X_flat[train_index], X_flat[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train SVM\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_accuracy = svm.score(X_test, y_test)\n",
    "    svm_accuracies.append(svm_accuracy)\n",
    "\n",
    "# Loop over the folds for Random Forest\n",
    "for train_index, test_index in kf.split(X_flat, y):\n",
    "    X_train, X_test = X_flat[train_index], X_flat[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_accuracy = rf.score(X_test, y_test)\n",
    "    rf_accuracies.append(rf_accuracy)\n",
    "\n",
    "# Calculate mean accuracies\n",
    "mean_svm_accuracy = sum(svm_accuracies) / len(svm_accuracies)\n",
    "mean_rf_accuracy = sum(rf_accuracies) / len(rf_accuracies)\n",
    "\n",
    "print(f\"Mean SVM Accuracy: {mean_svm_accuracy:.2f}\")\n",
    "print(f\"Mean Random Forest Accuracy: {mean_rf_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton (nn)",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
